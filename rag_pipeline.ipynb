{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e7b009",
   "metadata": {},
   "source": [
    "# RAG Pipeline\n",
    "\n",
    "This notebook contains the full pipeline structure. Fill in sections as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c96622",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a9b778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: langgraph in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: ragas in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.6)\n",
      "Requirement already satisfied: pypdf in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.11)\n",
      "Requirement already satisfied: rank-bm25 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.2.2)\n",
      "Requirement already satisfied: pinecone-text in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (0.2.12)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.53)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (23.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (8.4.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.12.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (1.0.0)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: groq<1.0.0,>=0.30.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-groq) (0.37.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (4.4.1)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (0.7.0)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (1.1.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: openai>1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (1.109.1)\n",
      "Requirement already satisfied: pysbd>=0.3.4 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ragas) (0.3.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (0.20.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-text) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-text) (3.9.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-text) (2.32.0.20240712)\n",
      "Requirement already satisfied: joblib in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text) (1.4.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>1->ragas) (0.4.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->ragas) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->ragas) (2.2.2)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets->ragas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets->ragas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\junke\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-groq sentence-transformers faiss-cpu langgraph ragas pypdf spacy rank-bm25 transformers accelerate pinecone-client pinecone-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d0a85b-f1f6-4b48-8533-db84cfe4cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------  12.6/12.8 MB 65.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 53.6 MB/s  0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a0361",
   "metadata": {},
   "source": [
    "## 2. Load PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56eb96ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "pdf_path = \"Deepseek-r1.pdf\"\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76925ef",
   "metadata": {},
   "source": [
    "## 3. Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a1ebf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"-\\n\", \"\", text)  # fix hyphen-newlines\n",
    "    text = re.sub(r\"\\n\", \" \", text)  # flatten newlines\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_docs = []\n",
    "for d in docs:\n",
    "    cleaned_docs.append(clean_text(d.page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcb60f",
   "metadata": {},
   "source": [
    "## 4. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb59696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed chunks: 136\n",
      "Semantic chunks: 75\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import spacy\n",
    "\n",
    "# load spacy for semantic chunking\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 1. Fixed Chunking\n",
    "fixed_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "fixed_chunks = fixed_splitter.create_documents(cleaned_docs)\n",
    "\n",
    "# 2. Semantic Chunking\n",
    "def semantic_chunk(text, max_tokens=120):\n",
    "    doc = nlp(text)\n",
    "    chunks = []\n",
    "    current = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        current.append(sent.text)\n",
    "        if len(\" \".join(current).split()) > max_tokens:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current = []\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "    return chunks\n",
    "\n",
    "semantic_chunks = []\n",
    "for d in cleaned_docs:\n",
    "    semantic_chunks.extend(semantic_chunk(d))\n",
    "\n",
    "print(\"Fixed chunks:\", len(fixed_chunks))\n",
    "print(\"Semantic chunks:\", len(semantic_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e99bca0",
   "metadata": {},
   "source": [
    "## 5.1. Initialize Embedding Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f142ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize embedding model\n",
    "embed_model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0877bb9",
   "metadata": {},
   "source": [
    "## 5.2. Pinecone Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "413ea6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "# Get Pinecone API key from environment variables\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\"Please set PINECONE_API_KEY environment variable or configure it in .env file\")\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"rag-semantic-index\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embed_model.get_sentence_embedding_dimension(),\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72f05b21-9495-48c6-816e-3307b951e12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 75/75 vectors\n",
      "All vectors uploaded, total: 75\n"
     ]
    }
   ],
   "source": [
    "vectors = []\n",
    "batch_size = 100  # Process in batches to avoid uploading too many at once\n",
    "\n",
    "for i, text in enumerate(semantic_chunks):\n",
    "    emb = embed_model.encode(text, show_progress_bar=False).tolist()\n",
    "    vectors.append({\n",
    "        \"id\": str(i),\n",
    "        \"values\": emb,\n",
    "        \"metadata\": {\"text\": text[:500]}  # Limit metadata length\n",
    "    })\n",
    "\n",
    "# Batch upload\n",
    "for i in range(0, len(vectors), batch_size):\n",
    "    batch = vectors[i:i + batch_size]\n",
    "    index.upsert(vectors=batch)\n",
    "    print(f\"Uploaded {min(i + batch_size, len(vectors))}/{len(vectors)} vectors\")\n",
    "\n",
    "print(f\"All vectors uploaded, total: {len(vectors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfa1c1",
   "metadata": {},
   "source": [
    "## 5.3. Reranker model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4013dae9-cd4a-4f1b-9533-ff591ec8146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BM25\n",
    "tokenized_corpus = [doc.split() for doc in semantic_chunks]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "def vector_search_pinecone(query, top_k=10):\n",
    "\n",
    "    q_emb = embed_model.encode(query, show_progress_bar=False).tolist()\n",
    "    res = index.query(\n",
    "        vector=q_emb,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    return res.get(\"matches\", [])\n",
    "\n",
    "def hybrid_search(query, alpha=0.5, top_k=10):\n",
    "\n",
    "    # BM25 scores\n",
    "    query_tokens = query.split()\n",
    "    if not query_tokens:\n",
    "        return []\n",
    "    \n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    # Normalize BM25 scores\n",
    "    if np.max(bm25_scores) - np.min(bm25_scores) > 1e-9:\n",
    "        bm25_norm = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "    else:\n",
    "        bm25_norm = np.ones_like(bm25_scores) * 0.5\n",
    "\n",
    "    # Pinecone vector search\n",
    "    vector_results = vector_search_pinecone(query, top_k=top_k * 2)  # Get more candidates\n",
    "    \n",
    "    vector_scores = np.zeros(len(semantic_chunks))\n",
    "    for m in vector_results:\n",
    "        idx = int(m[\"id\"])\n",
    "        if 0 <= idx < len(semantic_chunks):\n",
    "            vector_scores[idx] = m.get(\"score\", 0.0)\n",
    "\n",
    "    # Normalize vector scores\n",
    "    if np.max(vector_scores) - np.min(vector_scores) > 1e-9:\n",
    "        vector_norm = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores))\n",
    "    else:\n",
    "        vector_norm = np.ones_like(vector_scores) * 0.5\n",
    "\n",
    "    # Hybrid score\n",
    "    hybrid = alpha * bm25_norm + (1 - alpha) * vector_norm\n",
    "\n",
    "    # Top K results\n",
    "    best_idx = np.argsort(hybrid)[::-1][:top_k]\n",
    "\n",
    "    return [(i, float(hybrid[i]), semantic_chunks[i]) for i in best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5481a6-effe-4390-9db0-9ff588477698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Reranker model...\n",
      "Reranker model loaded\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "print(\"Loading Reranker model...\")\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"BAAI/bge-reranker-base\"\n",
    ")\n",
    "reranker_tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-base\")\n",
    "reranker_model.eval()  # Set to evaluation mode\n",
    "print(\"Reranker model loaded\")\n",
    "\n",
    "def rerank(query, candidates, top_k=5):\n",
    "\n",
    "    if not candidates:\n",
    "        return []\n",
    "    \n",
    "    pairs = [[query, c[2]] for c in candidates]\n",
    "    inputs = reranker_tokenizer(\n",
    "        pairs,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,  # Limit max length\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        scores = reranker_model(**inputs).logits.squeeze()\n",
    "    \n",
    "    # Handle single result case\n",
    "    if scores.dim() == 0:\n",
    "        scores = scores.unsqueeze(0)\n",
    "    \n",
    "    scored = list(zip(scores.tolist(), candidates))\n",
    "    scored.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    return scored[:top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d12f4",
   "metadata": {},
   "source": [
    "## 6. Groq LLM (RAG Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3bd651c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq LLM initialized\n",
      "\n",
      "Test query: What is the main contribution of DeepSeek-R1?\n",
      "\n",
      "Answer:\n",
      "The principal contribution of **DeepSeek‑R1** is a new training pipeline that combines a small, high‑quality “cold‑start” dataset of long, human‑friendly Chains‑of‑Thought with reinforcement‑learning fine‑tuning. By first fine‑tuning the base model on this readable CoT data and then applying RL, DeepSeek‑R1 produces a model that:\n",
      "\n",
      "* Generates clear, coherent, and user‑friendly Chains‑of‑Thought, addressing the readability and language‑mixing problems observed in DeepSeek‑R1‑Zero.  \n",
      "* Retains the strong reasoning and general‑purpose capabilities of the underlying model.  \n",
      "\n",
      "In short, DeepSeek‑R1’s main contribution is the **integration of a human‑oriented cold‑start fine‑tuning step with RL to create a reasoning model that is both powerful and easy to read**.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import os\n",
    "from typing import List, Tuple, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Groq API key from environment variables\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000\n",
    ")\n",
    "print(\"Groq LLM initialized\")\n",
    "\n",
    "def retrieve(query, top_k=5, alpha=0.5):\n",
    "\n",
    "    # Hybrid search\n",
    "    hybrid_results = hybrid_search(query, alpha=alpha, top_k=20)\n",
    "    \n",
    "    if not hybrid_results:\n",
    "        print(\"No relevant documents found\")\n",
    "        return []\n",
    "    \n",
    "    # Rerank\n",
    "    reranked_results = rerank(query, hybrid_results, top_k=top_k)\n",
    "    \n",
    "    # Extract texts\n",
    "    retrieved_texts = [r[1][2] for r in reranked_results]\n",
    "    return retrieved_texts\n",
    "    \n",
    "def rag_answer(query, top_k=5):\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    ctx = retrieve(query, top_k=top_k)\n",
    "    \n",
    "    if not ctx:\n",
    "        return \"Sorry, no relevant information found.\"\n",
    "    \n",
    "    # Build prompt\n",
    "    context_text = \"\\n\\n\".join([f\"[Document {i+1}]: {text}\" for i, text in enumerate(ctx)])\n",
    "    \n",
    "    prompt = f\"\"\"Answer the question based on the following context. If the context does not contain relevant information, please state so.\n",
    "\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Call LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Extract text content\n",
    "    if hasattr(response, 'content'):\n",
    "        return response.content\n",
    "    else:\n",
    "        return str(response)\n",
    "\n",
    "# Test\n",
    "test_query = \"What is the main contribution of DeepSeek-R1?\"\n",
    "print(f\"\\nTest query: {test_query}\")\n",
    "answer = rag_answer(test_query)\n",
    "print(f\"\\nAnswer:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5e966-b547-4948-b558-0a724428d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# LLM Judge wrapper\n",
    "class GroqJudge:\n",
    "    def __init__(self, model: str = 'openai/gpt-oss-120b'):\n",
    "        self.llm = ChatGroq(model=model, temperature=0.0)\n",
    "\n",
    "    def __call__(self, prompt: str) -> str:\n",
    "        r = self.llm.invoke(prompt)\n",
    "        return r.content if hasattr(r, 'content') else str(r)\n",
    "\n",
    "\n",
    "judge_llm = GroqJudge()\n",
    "\n",
    "\n",
    "# Faithfulness evaluation\n",
    "def evaluate_faithfulness(answer: str, contexts: List[str]) -> float:\n",
    "    contexts_text = '\\n\\n'.join([f'[Document {i+1}]: {c}' for i, c in enumerate(contexts)])\n",
    "    prompt = f\"\"\"You are an evaluator. Evaluate how faithful the answer is to the context.\n",
    "\n",
    "Context:\n",
    "{contexts_text}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Output only a number 0-1.\"\"\"\n",
    "    text = judge_llm(prompt)\n",
    "    m = re.search(r'0?\\.\\d+|1\\.0|0', text)\n",
    "    return float(m.group()) if m else 0.0\n",
    "\n",
    "\n",
    "# Relevance evaluation\n",
    "def evaluate_relevance(question: str, answer: str) -> float:\n",
    "    prompt = f\"\"\"Evaluate how well the answer responds to the question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "{answer}\n",
    "\n",
    "Output only a number 0-1.\"\"\"\n",
    "    text = judge_llm(prompt)\n",
    "    m = re.search(r'0?\\.\\d+|1\\.0|0', text)\n",
    "    return float(m.group()) if m else 0.0\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def evaluate_context_recall(question: str, contexts: List[str]) -> float:\n",
    "    if not contexts:\n",
    "        return 0.0\n",
    "    q_emb = embed_model.encode(question, show_progress_bar=False)\n",
    "    ctx_embs = embed_model.encode(contexts, show_progress_bar=False)\n",
    "    sims = [cosine_similarity(q_emb, c) for c in ctx_embs]\n",
    "    return max(sims) if sims else 0.0\n",
    "\n",
    "def evaluate_rag(query: str, answer: str, contexts: List[str]) -> Dict[str, float]:\n",
    "    return {\n",
    "        \"faithfulness\": evaluate_faithfulness(answer, contexts),\n",
    "        \"relevance\": evaluate_relevance(query, answer),\n",
    "        \"context_recall\": evaluate_context_recall(query, contexts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa50e64-a04b-44c0-8ea0-05e18f0d5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RERANK_SCORE_THRESHOLD = 0.20\n",
    "COS_SIM_THRESHOLD      = 0.45\n",
    "LEX_OVERLAP_MIN        = 1\n",
    "CANDIDATE_MULTIPLIER   = 3\n",
    "\n",
    "# Simple tokenizer + stopwords\n",
    "_STOP = set((\"the a an and or of to is are was were be been being for with on at from by in into than as that this these those it its\".split()))\n",
    "def _tok(s: str):\n",
    "    import re\n",
    "    return [t for t in re.split(r\"[^A-Za-z0-9]+\", s.lower()) if len(t) >= 2 and t not in _STOP]\n",
    "\n",
    "def _cos(a, b):\n",
    "    na, nb = np.linalg.norm(a), np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def _texts_from_hybrid(hybrid_results):\n",
    "\n",
    "    texts = []\n",
    "    for x in hybrid_results:\n",
    "        if isinstance(x, (list, tuple)) and len(x) >= 3 and isinstance(x[2], str):\n",
    "            texts.append(x[2])\n",
    "        elif isinstance(x, dict):\n",
    "            md = x.get(\"metadata\") or {}\n",
    "            t = md.get(\"text\")\n",
    "            if isinstance(t, str):\n",
    "                texts.append(t)\n",
    "        elif isinstance(x, str):\n",
    "            texts.append(x)\n",
    "    return texts\n",
    "\n",
    "def _unpack_reranked(reranked):\n",
    "\n",
    "    texts, score_map = [], {}\n",
    "    for item in reranked:\n",
    "        # Try to detect (score, payload) vs (payload, score)\n",
    "        if isinstance(item, (list, tuple)) and len(item) == 2:\n",
    "            a, b = item\n",
    "            if isinstance(a, (int, float)) and not isinstance(b, (int, float)):\n",
    "                score, payload = float(a), b\n",
    "            elif isinstance(b, (int, float)) and not isinstance(a, (int, float)):\n",
    "                score, payload = float(b), a\n",
    "            else:\n",
    "                continue  # ambiguous → skip\n",
    "\n",
    "            # Extract text from payload\n",
    "            if isinstance(payload, (list, tuple)):\n",
    "                # Common candidate shape: (idx, hybrid_score, text)\n",
    "                text = payload[2] if len(payload) >= 3 and isinstance(payload[2], str) else (\n",
    "                    payload[-1] if isinstance(payload[-1], str) else None\n",
    "                )\n",
    "            elif isinstance(payload, dict):\n",
    "                text = payload.get(\"metadata\", {}).get(\"text\")\n",
    "            elif isinstance(payload, str):\n",
    "                text = payload\n",
    "            else:\n",
    "                text = None\n",
    "\n",
    "            if isinstance(text, str):\n",
    "                texts.append(text)\n",
    "                score_map[text] = score\n",
    "\n",
    "        elif isinstance(item, str):\n",
    "            texts.append(item)\n",
    "\n",
    "    return texts, score_map\n",
    "\n",
    "def retrieve(query: str, top_k: int = 5, alpha: float = 0.5) -> List[str]:\n",
    "\n",
    "    # 1) Expand candidate pool\n",
    "    pool_k = max(top_k * CANDIDATE_MULTIPLIER, 15)\n",
    "    hybrid_results = hybrid_search(query, alpha=alpha, top_k=pool_k) or []\n",
    "    if not hybrid_results:\n",
    "        print(\"[RETRIEVE] hybrid results empty\")\n",
    "        return []\n",
    "\n",
    "    # 2) Cross-encoder rerank\n",
    "    reranked_raw = rerank(query, hybrid_results, top_k=pool_k) or []\n",
    "    reranked_texts, score_map = _unpack_reranked(reranked_raw)\n",
    "\n",
    "    # 3) Normalize candidate texts for similarity computation\n",
    "    texts_for_sim = reranked_texts if reranked_texts else _texts_from_hybrid(hybrid_results)\n",
    "    if not texts_for_sim:\n",
    "        print(\"[RETRIEVE] no usable candidate texts\")\n",
    "        return []\n",
    "\n",
    "    # 4) Compute semantic similarity\n",
    "    try:\n",
    "        q_emb = embed_model.encode(query, show_progress_bar=False)\n",
    "        t_embs = embed_model.encode(texts_for_sim, show_progress_bar=False)\n",
    "        sims = [_cos(q_emb, te) for te in t_embs]\n",
    "    except Exception as e:\n",
    "        print(\"[RETRIEVE] embedding similarity failed:\", e)\n",
    "        sims = [0.0] * len(texts_for_sim)\n",
    "\n",
    "    # 5) Compute lexical overlap\n",
    "    q_toks = set(_tok(query))\n",
    "    overlaps = []\n",
    "    for t in texts_for_sim:\n",
    "        dtoks = set(_tok(t))\n",
    "        overlaps.append(len(q_toks & dtoks))\n",
    "\n",
    "    # 6) Apply gating filters\n",
    "    gated = []\n",
    "    for i, t in enumerate(texts_for_sim):\n",
    "        rerank_score = score_map.get(t, -1e9)  # missing → extremely low score\n",
    "        cos_score    = sims[i]\n",
    "        overlap_cnt  = overlaps[i]\n",
    "        if (\n",
    "            rerank_score >= RERANK_SCORE_THRESHOLD\n",
    "            and cos_score >= COS_SIM_THRESHOLD\n",
    "            and overlap_cnt >= LEX_OVERLAP_MIN\n",
    "        ):\n",
    "            gated.append((rerank_score, t, cos_score, overlap_cnt))\n",
    "\n",
    "    # 7) Sort & truncate by cross-encoder score\n",
    "    gated.sort(key=lambda x: x[0], reverse=True)\n",
    "    final_texts = [t for (_, t, __, ___) in gated[:top_k]]\n",
    "\n",
    "    print(\n",
    "        f\"Checking\"\n",
    "    )\n",
    "    return final_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988b1d9-3930-41fe-8985-13217a71244d",
   "metadata": {},
   "source": [
    "## 7. LangGraph Integration - Agentic RAG Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "947715d8-4224-4ba7-907c-c9497ed2ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "import operator\n",
    "from typing import TypedDict, Annotated, Sequence, Dict, List\n",
    "\n",
    "class RAGState(TypedDict):\n",
    "    query: str\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    has_contexts: bool\n",
    "    retrieved_contexts: list\n",
    "    answer: str\n",
    "    evaluation_results: dict\n",
    "    needs_refinement: bool\n",
    "    iteration_count: int\n",
    "\n",
    "def retrieve_node(state: RAGState) -> Command[RAGState]:\n",
    "    q = state[\"query\"]\n",
    "    ctx = retrieve(q, top_k=5)\n",
    "    has_ctx = len(ctx) > 0\n",
    "    print(f\"[RETRIEVE] has_contexts={has_ctx} (n={len(ctx)}) -> {'RAG' if has_ctx else 'GENERAL'}\")\n",
    "    return Command(update={\n",
    "        \"retrieved_contexts\": ctx,\n",
    "        \"has_contexts\": has_ctx,\n",
    "        \"messages\": [HumanMessage(content=f\"Retrieved {len(ctx)} documents (filtered)\")]\n",
    "    })\n",
    "\n",
    "def generate_node(state: RAGState) -> Command[RAGState]:\n",
    "    ctx = state[\"retrieved_contexts\"]\n",
    "    q = state[\"query\"]\n",
    "    if not ctx:\n",
    "        answer = \"Sorry, no relevant information found in the knowledge base.\"\n",
    "    else:\n",
    "        ctx_text = \"\\n\\n\".join([f\"[Document {i+1}]: {t}\" for i, t in enumerate(ctx)])\n",
    "        prompt = f\"\"\"Answer the question based on the following context. If the context does not contain relevant information, please state so.\n",
    "\n",
    "Context:\n",
    "{ctx_text}\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        r = llm.invoke(prompt)\n",
    "        answer = r.content if hasattr(r, \"content\") else str(r)\n",
    "    print(f\"[GENERATE] answer_len={len(answer)}\")\n",
    "    return Command(update={\"answer\": answer, \"messages\": [AIMessage(content=answer)]})\n",
    "\n",
    "def evaluate_node(state: RAGState) -> Command[RAGState]:\n",
    "    q, a, ctx = state[\"query\"], state[\"answer\"], state[\"retrieved_contexts\"]\n",
    "    if not ctx:\n",
    "        results = {\"faithfulness\": 0.0, \"relevance\": 0.0, \"context_recall\": 0.0}\n",
    "    else:\n",
    "        results = evaluate_rag(q, a, ctx) \n",
    "    avg = sum(results.values()) / (len(results) or 1)\n",
    "    need = (avg < 0.7) and (state[\"iteration_count\"] < 2)\n",
    "    print(f\"[EVALUATE] avg={avg:.3f} needs_refine={need}\")\n",
    "    return Command(update={\n",
    "        \"evaluation_results\": results,\n",
    "        \"needs_refinement\": need,\n",
    "        \"iteration_count\": state[\"iteration_count\"] + 1\n",
    "    })\n",
    "\n",
    "def refine_node(state: RAGState) -> Command[RAGState]:\n",
    "    original_query = state[\"query\"]\n",
    "    prompt = f\"\"\"The previous answer to the question \"{original_query}\" had low quality scores.\n",
    "Please generate an improved version of this question that might help retrieve more relevant documents.\n",
    "Output only the refined question, nothing else.\"\"\"\n",
    "    r = llm.invoke(prompt)\n",
    "    refined = r.content if hasattr(r, \"content\") else str(r)\n",
    "    print(f\"[REFINE] refined: {refined}\")\n",
    "    return Command(update={\n",
    "        \"query\": refined,\n",
    "        \"messages\": [HumanMessage(content=f\"Refining query: {refined}\")]\n",
    "    })\n",
    "\n",
    "def general_node(state: RAGState) -> Command[RAGState]:\n",
    "    q = state[\"query\"]\n",
    "    prompt = f\"\"\"You are a helpful assistant. Answer the following question directly and concisely.\n",
    "\n",
    "Question: {q}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    r = llm.invoke(prompt)\n",
    "    answer = r.content if hasattr(r, \"content\") else str(r)\n",
    "    print(f\"[GENERAL] answer_len={len(answer)}\")\n",
    "    return Command(update={\"answer\": answer, \"messages\": [AIMessage(content=answer)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418a19e8-db93-432d-b2ee-b5aaa10317ce",
   "metadata": {},
   "source": [
    "## 8. Build and Run the LangGraph Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f3cb4ce3-9f97-4b8d-8845-0ac72b6e6b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUERY: What is the main contribution of DeepSeek-R1?\n",
      "Checking\n",
      "[RETRIEVE] has_contexts=True (n=1) -> RAG\n",
      "[GENERATE] answer_len=700\n",
      "[EVALUATE] avg=0.846 needs_refine=False\n",
      "has_contexts: True\n",
      "answer The primary contribution of DeepSeek‑R1 is that it shows, for the first time in open research, that the reasoning abilities of large language models can be significantly improved **purely through large‑scale reinforcement learning applied directly to the base model, without any prior supervised fine‑tuning**. By using a pipeline that includes two RL stages (to discover better reasoning patterns and align with human preferences) together with two SFT seed stages, DeepSeek‑R1‑Zero achieves advanced chain‑of‑thought capabilities such as self‑verification, reflection, and the generation of long, coherent reasoning traces. This demonstrates that RL alone can incentivize and enhance LLM reasoning.\n",
      "\n",
      "=== QUERY: what is the weather like today?\n",
      "Checking\n",
      "[RETRIEVE] has_contexts=False (n=0) -> GENERAL\n",
      "[GENERAL] answer_len=119\n",
      "has_contexts: False\n",
      "answer I don’t have real‑time weather data. Please specify a location (or check a weather service) for the current conditions.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def build_rag_graph():\n",
    "    g = StateGraph(RAGState)\n",
    "\n",
    "    g.add_node(\"retrieve\", retrieve_node)  \n",
    "    g.add_node(\"generate\", generate_node)  \n",
    "    g.add_node(\"evaluate\", evaluate_node)  \n",
    "    g.add_node(\"refine\", refine_node)    \n",
    "    g.add_node(\"general\", general_node) \n",
    "\n",
    "    g.add_edge(START, \"retrieve\")\n",
    "\n",
    "    def after_retrieve(state: RAGState):\n",
    "        return \"generate\" if state.get(\"has_contexts\", False) else \"general\"\n",
    "\n",
    "    g.add_conditional_edges(\"retrieve\", after_retrieve, {\n",
    "        \"generate\": \"generate\",\n",
    "        \"general\": \"general\"\n",
    "    })\n",
    "\n",
    "    g.add_edge(\"generate\", \"evaluate\")\n",
    "\n",
    "    def after_eval(state: RAGState):\n",
    "        return \"refine\" if state.get(\"needs_refinement\", False) else \"end\"\n",
    "\n",
    "    g.add_conditional_edges(\"evaluate\", after_eval, {\n",
    "        \"refine\": \"refine\",\n",
    "        \"end\": END\n",
    "    })\n",
    "\n",
    "    g.add_edge(\"refine\", \"retrieve\")\n",
    "\n",
    "    g.add_edge(\"general\", END)\n",
    "\n",
    "    return g.compile()\n",
    "\n",
    "rag_graph = build_rag_graph()\n",
    "\n",
    "def run_agentic_rag(query: str) -> Dict:\n",
    "    init_state = {\n",
    "        \"query\": query,\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"has_contexts\": False,\n",
    "        \"retrieved_contexts\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"evaluation_results\": {},\n",
    "        \"needs_refinement\": False,\n",
    "        \"iteration_count\": 0\n",
    "    }\n",
    "    final_state = rag_graph.invoke(init_state)\n",
    "    return final_state\n",
    "\n",
    "test_queries = [\n",
    "    \"What is the main contribution of DeepSeek-R1?\",\n",
    "    \"what is the weather like today?\"\n",
    "]\n",
    "for q in test_queries:\n",
    "    print(\"=== QUERY:\", q)\n",
    "    res = run_agentic_rag(q)\n",
    "    print(\"has_contexts:\", res.get(\"has_contexts\"))\n",
    "    print(\"answer\", (res.get(\"answer\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f6aea424-1d34-46f5-a422-be6871edc078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(rag_graph.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
